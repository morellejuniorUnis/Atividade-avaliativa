{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkaIIUpYaz9f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount\t('/content/drive')\n",
        "drive_path = '/content/drive/MyDrive/FilesForAiDetection'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "files_for_detection = None\n",
        "image_file_extensions = ['.jpg', '.png', '.jpeg']\n",
        "video_file_extensions = ['.mp4']\n",
        "\n",
        "# Carregar a imagem\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    print(\"No images uploaded, using default\")\n",
        "    if not os.path.exists(drive_path):\n",
        "        print(\"Path for images and videos not found!\")\n",
        "        exit(0)\n",
        "    files_for_detection = [os.path.join(drive_path, drive_file) for drive_file in os.listdir(drive_path)]\n",
        "    if not files_for_detection:\n",
        "        print(\"No images or videos found in the path!\")\n",
        "        exit(0)\n",
        "else:\n",
        "    files_for_detection = list(uploaded.keys())"
      ],
      "metadata": {
        "id": "DmOxp7yqa2ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPENCV"
      ],
      "metadata": {
        "id": "aC-iWkH3dpMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Carregar o classificador em cascata para detecção de faces\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "\n",
        "def detect_faces(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=6)\n",
        "    return faces\n",
        "\n",
        "# Parâmetros do vídeo para salvar o resultado\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec para o formato MP4\n",
        "out = None\n",
        "\n",
        "# A imagem será salva no diretório atual\n",
        "for filename in files_for_detection:\n",
        "    if any([filename.endswith(file_extension) for file_extension in image_file_extensions]):\n",
        "        image = cv2.imread(filename)\n",
        "\n",
        "        # Converter BGR para GRAY para analisar corretamente\n",
        "        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        start_time = time.time()\n",
        "        faces = detect_faces(image)\n",
        "        end_time = time.time()\n",
        "        print(f\"Image detecting time: {end_time - start_time} seconds\")\n",
        "\n",
        "\n",
        "        # Desenhar retângulos ao redor das faces detectadas\n",
        "        for (x, y, w, h) in faces:\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 4)\n",
        "\n",
        "        cv2_imshow(image)\n",
        "    elif any([filename.endswith(file_extension) for file_extension in video_file_extensions]):\n",
        "        cap = cv2.VideoCapture(filename)\n",
        "        start_time = time.time()\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            faces = detect_faces(frame)\n",
        "\n",
        "            for (x, y, w, h) in faces:\n",
        "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "            if out is None:\n",
        "                height, width = frame.shape[:2]\n",
        "                out = cv2.VideoWriter('output_pessoas_detectadas.mp4', fourcc, 30.0, (width, height))\n",
        "\n",
        "            # Escreve o frame processado no vídeo de saída\n",
        "            out.write(frame)\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(f\"Video detecting time: {end_time - start_time} seconds\")\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        files.download('output_pessoas_detectadas.mp4')\n"
      ],
      "metadata": {
        "id": "e5LafDMya3H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DLIB"
      ],
      "metadata": {
        "id": "cuZG5DvPa6Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dlib\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "hog_detector = dlib.get_frontal_face_detector()\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec para o formato MP4\n",
        "out = None\n",
        "\n",
        "\n",
        "for filename in files_for_detection:\n",
        "    if any([filename.endswith(file_extension) for file_extension in image_file_extensions]):\n",
        "        image = cv2.imread(filename)\n",
        "\n",
        "        # Converter BGR para GRAY para analisar corretamente\n",
        "        image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        start_time = time.time()\n",
        "        faces = hog_detector(image, 1)\n",
        "        end_time = time.time()\n",
        "        print(f\"Image detecting time: {end_time - start_time} seconds\")\n",
        "\n",
        "        # Desenhar retângulos ao redor das faces detectadas\n",
        "        for face in faces:\n",
        "            x1 = face.left()\n",
        "            y1 = face.top()\n",
        "            x2 = face.right()\n",
        "            y2 = face.bottom()\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 4)\n",
        "\n",
        "        cv2_imshow(image)\n",
        "    elif any([filename.endswith(file_extension) for file_extension in video_file_extensions]):\n",
        "        cap = cv2.VideoCapture(filename)\n",
        "\n",
        "        start_time = time.time()\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            faces = hog_detector(frame, 1)\n",
        "\n",
        "            # Desenhar retângulos ao redor das faces detectadas\n",
        "            for face in faces:\n",
        "                x1 = face.left()\n",
        "                y1 = face.top()\n",
        "                x2 = face.right()\n",
        "                y2 = face.bottom()\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "            if out is None:\n",
        "                height, width = frame.shape[:2]\n",
        "                out = cv2.VideoWriter('output_pessoas_detectadas.mp4', fourcc, 30.0, (width, height))\n",
        "\n",
        "            # Escreve o frame processado no vídeo de saída\n",
        "            out.write(frame)\n",
        "\n",
        "        end_time = time.time()\n",
        "        print(f\"Video detecting time: {end_time - start_time} seconds\")\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        files.download('output_pessoas_detectadas.mp4')"
      ],
      "metadata": {
        "id": "74oTfszRa4-T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}